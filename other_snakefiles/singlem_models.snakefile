# This snakefile contains rules that were removed from the main Snakefile.
# These rules build and assess models built on the output of the singlem tool.
# SingleM identifies and estimates the abundance of single copy marker genes in short shotgun metagenome sequencing reads.
# These sequences are used to infer the taxnomomic composition of the metagenome.
# These analyses did not make it into the final IBD paper. 
# For a write up of these results, see my thesis: https://github.com/taylorreiter/2020-dissertation
# Chapter 4: https://github.com/taylorreiter/2020-dissertation/blob/main/thesis/04-ibd.Rmd#L155
# Rendered document: https://github.com/taylorreiter/2020-dissertation/releases/download/2020_11_18/thesis.pdf

# If the main Snakefile has been executed, the code in this snakefile should run. 
# However, the code relies on the abundance trimmed reads and other files generated by the main pipeline, so this is not a standalone executable pipeline file.

import pandas as pd
#import feather
import numpy as np
from sourmash import signature
import sourmash
import glob
import os
import csv
import re

TMPDIR = "/scratch/tereiter/"

SEED = [1, 2, 3, 4, 5, 6]
ABUNDANCE = ['increased', 'decreased']

m = pd.read_csv("inputs/working_metadata.tsv", sep = "\t", header = 0)
SAMPLES = m.sort_values(by='read_count')['run_accession']
LIBRARIES = m['library_name'].unique().tolist()
STUDY = m['study_accession'].unique().tolist()

########################################
## Try singlem on abundtrim
########################################

rule split_paired_reads_abundtrim:
    input: "outputs/abundtrim/{library}.abundtrim.fq.gz"
    output: 
        O = "outputs/abundtrim_split/{library}_orphan.abundtrim.fq.gz",
        R1 = "outputs/abundtrim_split/{library}_R1.abundtrim.fq.gz",
        R2 = "outputs/abundtrim_split/{library}_R2.abundtrim.fq.gz"
    conda: "envs/env.yml"
    threads: 1
    resources:
        mem_mb=4000
    shell:'''
    split-paired-reads.py -0 {output.O} -1 {output.R1} -2 {output.R2} --gzip {input}    
    '''

rule singlem_default_abundtrim:
    input: 
        R1 = "outputs/abundtrim_split/{library}_R1.abundtrim.fq.gz",
        R2 = "outputs/abundtrim_split/{library}_R2.abundtrim.fq.gz"
    output: "outputs/singlem_abundtrim/{library}_otu_default.csv"
    conda: "envs/singlem.yml"
    threads: 2
    resources:
        mem_mb=4000
    shell: '''
    singlem pipe --forward {input.R1} --reverse {input.R2} --otu_table {output} --output_extras --threads {threads} --filter_minimum_nucleotide 36 --min_orf_length 36 --filter_minimum_protein 12 #|| touch {output}
    touch {output} # creates output file for runs with no seq matches
    '''

rule singlem_16s_abundtrim_R1:
    input: 
        R1 = "outputs/abundtrim_split/{library}_R1.abundtrim.fq.gz",
        pkg =  "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg/CONTENTS.json"
    output: "outputs/singlem_abundtrim/{library}_otu_16s_R1.csv"
    conda: "envs/singlem.yml"
    threads: 2
    resources:
        mem_mb=4000
    params: 
        pkg_dir = "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg"
    shell: '''
    singlem pipe --sequences {input.R1} --singlem_packages {params.pkg_dir} --otu_table {output} --output_extras --threads {threads} --filter_minimum_nucleotide 36 --min_orf_length 36 --filter_minimum_protein 12 # || touch {output}
    touch {output}
    '''

rule singlem_16s_abundtrim_R2:
    input: 
        R2 = "outputs/abundtrim_split/{library}_R2.abundtrim.fq.gz",
        pkg =  "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg/CONTENTS.json"
    output: "outputs/singlem_abundtrim/{library}_otu_16s_R2.csv"
    conda: "envs/singlem.yml"
    threads: 2
    resources:
        mem_mb=4000
    params: 
        pkg_dir = "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg"
    shell: '''
    singlem pipe --sequences {input.R2} --singlem_packages {params.pkg_dir} --otu_table {output} --output_extras --threads {threads} --filter_minimum_nucleotide 36 --min_orf_length 36 --filter_minimum_protein 12 # || touch {output}
    touch {output}
    '''

rule combine_singlem_abundtrim:
    input:
        default = expand("outputs/singlem_abundtrim/{library}_otu_default.csv", library = LIBRARIES),
        s16_R1 = expand("outputs/singlem_abundtrim/{library}_otu_16s_R1.csv", library = LIBRARIES),
        s16_R2 = expand("outputs/singlem_abundtrim/{library}_otu_16s_R2.csv", library = LIBRARIES)
    output: res = "outputs/singlem_abundtrim/combined.tsv"
    conda: "envs/tidy.yml"
    threads: 1
    resources:
        mem_mb=16000
    script: "scripts/parse_singlem_abundtrim.R"

rule singlem_to_counts_abuntrim:
    input:  res = "outputs/singlem_abundtrim/combined.tsv"
    output: counts = "outputs/singlem_abundtrim/singlem_counts.tsv"
    conda: "envs/tidy.yml"
    threads: 1
    resources:
        mem_mb=16000
    script: "scripts/make_singlem_counts_abundtrim.R"

rule singlem_abundtrim_install_pomona:
    input: "outputs/singlem_abundtrim/combined.tsv"
    output:
        pomona = "outputs/singlem_abundtrim_vita_rf/pomona_install.txt"
    conda: 'envs/rf.yml'
    threads: 1
    resources:
        mem_mb=1000
    script: "scripts/install_pomona.R"

rule singlem_abundtrim_var_sel_rf:
    input:
        info = "inputs/working_metadata.tsv", 
        counts = "outputs/singlem_abundtrim/singlem_counts.tsv",
        pomona = "outputs/singlem_abundtrim_vita_rf/pomona_install.txt"
    output:
        vita_rf = "outputs/singlem_abundtrim_vita_rf/{study}_vita_rf.RDS",
        vita_vars = "outputs/singlem_abundtrim_vita_rf/{study}_vita_vars.txt",
        ibd_filt = "outputs/singlem_abundtrim_vita_rf/{study}_ibd_filt.csv"
    threads: 6
    resources:
        mem_mb=32000
    params: 
        threads = 6,
        validation_study = "{study}"
    conda: 'envs/rf.yml'
    script: "scripts/singlem_vita_rf.R"

rule singlem_abundtrim_loo_validation:
    input: 
        ibd_filt = 'outputs/singlem_abundtrim_vita_rf/{study}_ibd_filt.csv',
        info = 'inputs/working_metadata.tsv',
        eval_model = 'scripts/function_evaluate_model.R',
        ggconfusion = 'scripts/ggplotConfusionMatrix.R'
    output: 
        recommended_pars = 'outputs/singlem_abundtrim_optimal_rf/{study}_rec_pars.tsv',
        optimal_rf = 'outputs/singlem_abundtrim_optimal_rf/{study}_optimal_rf.RDS',
        training_accuracy = 'outputs/singlem_abundtrim_optimal_rf/{study}_training_acc.csv',
        training_confusion = 'outputs/singlem_abundtrim_optimal_rf/{study}_training_confusion.pdf',
        validation_accuracy = 'outputs/singlem_abundtrim_optimal_rf/{study}_validation_acc.csv',
        validation_confusion = 'outputs/singlem_abundtrim_optimal_rf/{study}_validation_confusion.pdf'
    threads: 6
    resources:
        mem_mb=8000
    params:
        threads = 6,
        validation_study = "{study}"
    conda: 'envs/tuneranger.yml'
    script: "scripts/singlem_tune_rf.R"

######## kmer model of singlem on abundtrim

######### default all

rule extract_singlem_read_names_default_abundtrim:
    input: singlem = "outputs/singlem_abundtrim/{library}_otu_default.csv",
    output: reads = "outputs/singlem_abundtrim_reads/{library}_otu_default_read_names.txt" 
    conda: "envs/tidy.yml"
    resources:
        mem_mb = 8000
    threads: 1
    script: "scripts/extract_singlem_read_names.R"

rule extract_singlem_reads_default:
    input: 
        names = "outputs/singlem_abundtrim_reads/{library}_otu_default_read_names.txt",
        fq = "outputs/abundtrim/{library}.abundtrim.fq.gz",
    output: "outputs/singlem_abundtrim_reads/{library}_otu_default.fq",
    conda: "envs/sourmash.yml"
    resources:
        mem_mb = 8000
    threads: 1
    shell:'''
    scripts/extract-aaseq-matches.py {input.names} {input.fq} > {output}
    '''

####### 16s R1
rule extract_singlem_read_names_16s_R1_abundtrim:
    input: singlem = "outputs/singlem_abundtrim/{library}_otu_16s_R1.csv",
    output: reads = "outputs/singlem_abundtrim_reads/{library}_otu_16s_R1_read_names.txt" 
    conda: "envs/tidy.yml"
    resources:
        mem_mb = 8000
    threads: 1
    script: "scripts/extract_singlem_read_names.R"

rule extract_singlem_reads_16s_R1_abundtrim:
    input: 
        names = "outputs/singlem_abundtrim_reads/{library}_otu_16s_R1_read_names.txt",
        fq = "outputs/abundtrim/{library}.abundtrim.fq.gz",
    output: "outputs/singlem_abundtrim_reads/{library}_otu_16s_R1.fq",
    conda: "envs/sourmash.yml"
    resources:
        mem_mb = 8000
    threads: 1
    shell:'''
    scripts/extract-aaseq-matches.py {input.names} {input.fq} > {output}
    '''

######### 16 R2

rule extract_singlem_read_names_16s_R2_abundtrim:
    input: singlem = "outputs/singlem_abundtrim/{library}_otu_16s_R2.csv",
    output: reads = "outputs/singlem_abundtrim_reads/{library}_otu_16s_R2_read_names.txt" 
    conda: "envs/tidy.yml"
    resources:
        mem_mb = 8000
    threads: 1
    script: "scripts/extract_singlem_read_names.R"

rule extract_singlem_reads_16s_R2_abundtrim:
    input: 
        names = "outputs/singlem_abundtrim_reads/{library}_otu_16s_R2_read_names.txt",
        fq = "outputs/abundtrim/{library}.abundtrim.fq.gz",
    output: "outputs/singlem_abundtrim_reads/{library}_otu_16s_R2.fq",
    conda: "envs/sourmash.yml"
    resources:
        mem_mb = 8000
    threads: 1
    shell:'''
    scripts/extract-aaseq-matches.py {input.names} {input.fq} > {output}
    '''

rule combine_singlem_reads_per_lib_abundtrim:
    input:
        "outputs/singlem_abundtrim_reads/{library}_otu_default.fq",
        "outputs/singlem_abundtrim_reads/{library}_otu_16s_R1.fq",
        "outputs/singlem_abundtrim_reads/{library}_otu_16s_R2.fq",
    output: "outputs/singlem_abundtrim_reads/{library}_singlem_reads.fq"
    resources:
        mem_mb = 8000
    threads: 1
    shell:'''
    cat {input} > {output}
    '''

rule compute_signatures_singlem:
    input: "outputs/singlem_abundtrim_reads/{library}_singlem_reads.fq"
    output: "outputs/singlem_abundtrim_sigs/{library}_singlem_reads.sig"
    conda: "envs/sourmash.yml"
    resources:
        mem_mb = 1000
    threads: 1
    shell:'''
    sourmash compute -k 31 --scaled 2000 -o {output} --track-abundance {input} || touch {output} 
    '''

rule convert_greater_than_1_signatures_to_csv_abundtrim:
    input: "outputs/singlem_abundtrim_sigs/{library}_singlem_reads.sig"
    output: "outputs/singlem_abundtrim_kmer_csv/{library}_singlem_reads.csv"
    conda: 'envs/sourmash.yml'
    resources: 
        mem_mb=1000
    threads: 1
    shell:'''
    python scripts/sig_to_csv.py {input} {output} || touch {output}
    '''

rule make_hash_abund_table_long_normalized_abundtrim:
    input: 
        expand("outputs/singlem_abundtrim_kmer_csv/{library}_singlem_reads.csv", library = LIBRARIES)
    output: csv = "outputs/singlem_abundtrim_kmer_hash_tables/normalized_abund_hashes_long.csv"
    conda: 'envs/r.yml'
    resources: 
        mem_mb=16000
    threads: 1
    script: "scripts/normalized_hash_abund_long_singlem.R"

rule make_hash_abund_table_wide_abundtrim:
    input: "outputs/singlem_abundtrim_kmer_hash_tables/normalized_abund_hashes_long.csv"
    output: "outputs/singlem_abundtrim_kmer_hash_tables/normalized_abund_hashes_wide.feather"
    resources: 
        mem_mb=32000
    threads: 1
    run:
        import pandas as pd
        import feather
        
        ibd = pd.read_csv(str(input), dtype = {"minhash" : "int64", "abund" : "float64", "sample" : "object"})
        ibd_wide=ibd.pivot(index='sample', columns='minhash', values='abund')
        ibd_wide = ibd_wide.fillna(0)
        ibd_wide['sample'] = ibd_wide.index
        ibd_wide = ibd_wide.reset_index(drop=True)
        ibd_wide.columns = ibd_wide.columns.astype(str)
        ibd_wide.to_feather(str(output)) 

rule singlem_kmer_install_pomona_abundtrim:
    input: "outputs/singlem_abundtrim_kmer_hash_tables/normalized_abund_hashes_wide.feather"
    output:
        pomona = "outputs/singlem_abundtrim_kmer_vita_rf/pomona_install.txt"
    conda: 'envs/rf.yml'
    resources: 
        mem_mb=1000
    threads: 1
    script: "scripts/install_pomona.R"

rule singlem_kmer_vita_var_sel_rf_abundtrim:
    input:
        info = "inputs/working_metadata.tsv", 
        feather = "outputs/singlem_abundtrim_kmer_hash_tables/normalized_abund_hashes_wide.feather",
        pomona = "outputs/singlem_abundtrim_kmer_vita_rf/pomona_install.txt"
    output:
        vita_rf = "outputs/singlem_abundtrim_kmer_vita_rf/{study}_vita_rf.RDS",
        vita_vars = "outputs/singlem_abundtrim_kmer_vita_rf/{study}_vita_vars.txt",
        ibd_filt = "outputs/singlem_abundtrim_kmer_vita_rf/{study}_ibd_filt.csv"
    resources: 
        mem_mb=16000
    threads: 4
    params: 
        threads = 4,
        validation_study = "{study}"
    conda: 'envs/rf.yml'
    script: "scripts/singlem_kmer_vita_rf.R"

rule singlem_kmer_loo_validation:
    input: 
        ibd_filt = 'outputs/singlem_abundtrim_kmer_vita_rf/{study}_ibd_filt.csv',
        info = 'inputs/working_metadata.tsv',
        eval_model = 'scripts/function_evaluate_model.R',
        ggconfusion = 'scripts/ggplotConfusionMatrix.R'
    output: 
        recommended_pars = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_rec_pars.tsv',
        optimal_rf = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_optimal_rf.RDS',
        training_accuracy = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_training_acc.csv',
        training_confusion = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_training_confusion.pdf',
        validation_accuracy = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_validation_acc.csv',
        validation_confusion = 'outputs/singlem_abundtrim_kmer_optimal_rf/{study}_validation_confusion.pdf'
    resources: 
        mem_mb=4000
    threads: 4
    params:
        threads = 4,
        validation_study = "{study}"
    conda: 'envs/tuneranger.yml'
    script: "scripts/tune_rf.R"

###########################################################
## SingleM Ribosomal gene abundance validation: SGC NBHDS
###########################################################

# The results in the thesis are from the first run of spacegraphcats.
# We re-ran spacegraphcats after identifying a bug that caused a reduced set of sequences to be returned when querying.
# This set of models was  never rerun, as we instead developed dominating set differential abundance analysis and graph annotation on the catlas.
#rule rename_sgc_nbhd_reads:
#    input: "outputs/sgc_genome_queries/{library}_k31_r1_search_oh0/{acc}_genomic.fna.gz.cdbg_ids.reads.gz"
#    output: "outputs/sgc_genome_queries_renamed/{library}/{acc}_renamed.fastq.gz"
#    resources:
#        mem_mb = 4000
#    threads: 1
#    shell:'''
#    zcat {input} | awk '{{print (NR%4 == 1) ? "@1_" ++i : $0}}' | gzip -c > {output}
#    '''
#
#rule singlem_default_nbhd_reads:
#    input: "outputs/sgc_genome_queries_renamed/{library}/{acc}_renamed.fastq.gz"
#    output: "outputs/singlem_sgc_genome_queries/{library}/{acc}_otu_default.csv"
#    conda: "envs/singlem.yml"
#    resources:
#        mem_mb = 16000
#    threads: 2
#    shell: '''
#    singlem pipe --sequences {input} --otu_table {output} --output_extras --threads {threads} --filter_minimum_nucleotide 36 --min_orf_length 36 --filter_minimum_protein 12 || touch {output}
#    touch {output} # creates output file for runs with no seq matches
#    '''
#
#rule download_singlem_16s_pkg:
#    output: "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg.tar.xz"
#    resources:
#        mem_mb = 1000
#    threads: 1
#    shell:'''
#    wget -O {output} https://github.com/wwood/singlem_extra_packages/raw/master/release1/4.40.2013_08_greengenes_97_otus.with_euks.spkg.tar.xz
#    '''
#
#rule untar_singlem_16s_pkg:
#    input:"inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg.tar.xz"
#    output: "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg/CONTENTS.json"
#    resources:
#        mem_mb = 1000
#    threads: 1
#    params: outdir = "inputs/singlem"
#    shell:'''
#    tar xf {input} -C {params.outdir}
#    '''
#
#rule singlem_16s_nbhd_reads:
#    input: 
#        seq = "outputs/sgc_genome_queries_renamed/{library}/{acc}_renamed.fastq.gz",
#        pkg =  "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg/CONTENTS.json"
#    output: "outputs/singlem_sgc_genome_queries/{library}/{acc}_otu_16s.csv"
#    conda: "envs/singlem.yml"
#    resources:
#        mem_mb = 16000
#    threads: 2
#    params: 
#        pkg_dir = "inputs/singlem/4.40.2013_08_greengenes_97_otus.with_euks.spkg"
#    shell: '''
#    singlem pipe --sequences {input.seq} --singlem_packages {params.pkg_dir} --otu_table {output} --output_extras --threads {threads} --filter_minimum_nucleotide 36 --min_orf_length 36 --filter_minimum_protein 12 || touch {output}
#    touch {output}
#    '''

# TR TODO: UPDATE TO CHECKPOINT INPUT
#rule combine_singlem_default:
#    input:
#        default = expand("outputs/singlem_sgc_genome_queries/{library}/{acc}_otu_default.csv", library = LIBRARIES, gather_genome = GATHER_GENOMES),
#    output: res = "outputs/singlem_sgc_genome_queries/combined_default.tsv"
#    conda: "envs/tidy.yml"
#    resources:
#        mem_mb = 16000
#    threads: 1
#    script: "scripts/parse_singlem_default.R"

# TR TODO: UPDATE TO CHECKPOINT INPUT
#rule combine_singlem_16s:
#    input:
#        s16 = expand("outputs/singlem_sgc_genome_queries/{library}/{acc}_otu_16s.csv", library = LIBRARIES, gather_genome = GATHER_GENOMES),
#    output: res = "outputs/singlem_sgc_genome_queries/combined_16s.tsv"
#    conda: "envs/tidy.yml"
#    resources:
#        mem_mb = 8000
#    threads: 1
#    script: "scripts/parse_singlem_16s.R"

# rule combine_singlem:
#     input: 
#         s16 = "outputs/singlem_sgc_genome_queries/combined_16s.tsv",
#         default = "outputs/singlem_sgc_genome_queries/combined_default.tsv"
#     output: res = "outputs/singlem_sgc_genome_queries/combined.tsv"
#     conda: "envs/tidy.yml"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     script: "scripts/parse_singlem.R"
# 
# rule singlem_to_counts:
#     input:  res = "outputs/singlem_sgc_genome_queries/combined.tsv"
#     output: counts = "outputs/singlem_sgc_genome_queries/singlem_counts.tsv"
#     conda: "envs/tidy.yml"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     script: "scripts/make_singlem_counts.R"
# 
# rule singlem_install_pomona:
#     input: "outputs/singlem_sgc_genome_queries/combined.tsv"
#     output:
#         pomona = "outputs/singlem_vita_rf/pomona_install.txt"
#     resources:
#         mem_mb = 1000
#     threads: 1
#     conda: 'envs/rf.yml'
#     script: "scripts/install_pomona.R"
# 
# rule singlem_var_sel_rf:
#     input:
#         info = "inputs/working_metadata.tsv", 
#         counts = "outputs/singlem_sgc_genome_queries/singlem_counts.tsv",
#         pomona = "outputs/singlem_vita_rf/pomona_install.txt"
#     output:
#         vita_rf = "outputs/singlem_vita_rf/{study}_vita_rf.RDS",
#         vita_vars = "outputs/singlem_vita_rf/{study}_vita_vars.txt",
#         ibd_filt = "outputs/singlem_vita_rf/{study}_ibd_filt.csv"
#     resources:
#         mem_mb = 64000
#     threads: 8
#     params: 
#         threads = 8,
#         validation_study = "{study}"
#     conda: 'envs/rf.yml'
#     script: "scripts/singlem_vita_rf.R"
# 
# 
# rule singlem_loo_validation:
#     input: 
#         ibd_filt = 'outputs/singlem_vita_rf/{study}_ibd_filt.csv',
#         info = 'inputs/working_metadata.tsv',
#         eval_model = 'scripts/function_evaluate_model.R',
#         ggconfusion = 'scripts/ggplotConfusionMatrix.R'
#     output: 
#         recommended_pars = 'outputs/singlem_optimal_rf/{study}_rec_pars.tsv',
#         optimal_rf = 'outputs/singlem_optimal_rf/{study}_optimal_rf.RDS',
#         training_accuracy = 'outputs/singlem_optimal_rf/{study}_training_acc.csv',
#         training_confusion = 'outputs/singlem_optimal_rf/{study}_training_confusion.pdf',
#         validation_accuracy = 'outputs/singlem_optimal_rf/{study}_validation_acc.csv',
#         validation_confusion = 'outputs/singlem_optimal_rf/{study}_validation_confusion.pdf'
#     resources:
#         mem_mb = 8000
#     threads: 8
#     params:
#         threads = 8,
#         validation_study = "{study}"
#     conda: 'envs/tuneranger.yml'
#     script: "scripts/singlem_tune_rf.R"
# 
# rule extract_singlem_read_names_default_sgc:
#     input: singlem = "outputs/singlem_sgc_genome_queries/{library}/{gather_genome}_otu_default.csv",
#     output: reads = "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_default_names.txt" 
#     conda: "envs/tidy.yml"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     script: "scripts/extract_singlem_read_names.R"
# 
# rule extract_singlem_reads_default_sgc:
#     input: 
#         names = "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_default_names.txt",
#         fq = "outputs/sgc_genome_queries_renamed/{library}/{gather_genome}_renamed.fastq.gz",
#     output: "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_default.fq",
#     conda: "envs/sourmash.yml"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     shell:'''
#     scripts/extract-aaseq-matches.py {input.names} {input.fq} > {output}
#     '''
# 
# rule extract_singlem_read_names_16s_sgc:
#     input: singlem = "outputs/singlem_sgc_genome_queries/{library}/{gather_genome}_otu_16s.csv",
#     output: reads = "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_16s_names.txt" 
#     conda: "envs/tidy.yml"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     script: "scripts/extract_singlem_read_names.R"
# 
# rule extract_singlem_reads_16s_sgc:
#     input: 
#         names = "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_16s_names.txt",
#         fq = "outputs/sgc_genome_queries_renamed/{library}/{gather_genome}_renamed.fastq.gz",
#     output: "outputs/singlem_sgc_genome_queries_reads/{library}/{gather_genome}_otu_16s.fq",
#     resources:
#         mem_mb = 8000
#     threads: 1
#     conda: "envs/sourmash.yml"
#     shell:'''
#     scripts/extract-aaseq-matches.py {input.names} {input.fq} > {output}
#     '''
# 
# rule combine_singlem_reads_per_lib_sgc:
#     input:
#         expand("outputs/singlem_sgc_genome_queries_reads/{{library}}/{gather_genome}_otu_default.fq", gather_genome = GATHER_GENOMES),
#         expand("outputs/singlem_sgc_genome_queries_reads/{{library}}/{gather_genome}_otu_16s.fq", gather_genome = GATHER_GENOMES)
#     output: "outputs/singlem_sgc_genome_queries_reads/{library}_singlem_reads.fq"
#     resources:
#         mem_mb = 8000
#     threads: 1
#     shell:'''
#     cat {input} > {output}
#     '''
# 
# ## run random forests on signatures of singlem output ###########################
#   
# rule compute_signatures_singlem_sgc:
#     input: "outputs/singlem_sgc_genome_queries_reads/{library}_singlem_reads.fq"
#     output: "outputs/singlem_sgc_genome_queries_sigs/{library}_singlem_reads.sig"
#     conda: "envs/sourmash.yml"
#     resources:
#         mem_mb = 1000
#     threads: 1
#     shell:'''
#     sourmash compute -k 31 --scaled 2000 -o {output} --track-abundance {input} || touch {output} 
#     '''
# 
# rule convert_greater_than_1_signatures_to_csv_singlem_sgc:
#     input: "outputs/singlem_sgc_genome_queries_sigs/{library}_singlem_reads.sig"
#     output: "outputs/singlem_sgc_genome_queries_kmer_csv/{library}_singlem_reads.csv"
#     conda: 'envs/sourmash.yml'
#     resources: 
#         mem_mb=1000
#     threads: 1
#     shell:'''
#     python scripts/sig_to_csv.py {input} {output} || touch {output}
#     '''
# 
# rule make_hash_abund_table_long_normalized_singlem_sgc:
#     input: 
#         expand("outputs/singlem_sgc_genome_queries_kmer_csv/{library}_singlem_reads.csv", library = LIBRARIES)
#     output: csv = "outputs/singlem_sgc_genome_queries_kmer_hash_tables/normalized_abund_hashes_long.csv"
#     conda: 'envs/r.yml'
#     resources: 
#         mem_mb=16000
#     threads: 1
#     script: "scripts/normalized_hash_abund_long_singlem.R"
# 
# rule make_hash_abund_table_wide_singlem_sgc:
#     input: "outputs/singlem_sgc_genome_queries_kmer_hash_tables/normalized_abund_hashes_long.csv"
#     output: "outputs/singlem_sgc_genome_queries_kmer_hash_tables/normalized_abund_hashes_wide.feather"
#     resources: 
#         mem_mb=32000
#     threads: 1
#     run:
#         import pandas as pd
#         import feather
#         
#         ibd = pd.read_csv(str(input), dtype = {"minhash" : "int64", "abund" : "float64", "sample" : "object"})
#         ibd_wide=ibd.pivot(index='sample', columns='minhash', values='abund')
#         ibd_wide = ibd_wide.fillna(0)
#         ibd_wide['sample'] = ibd_wide.index
#         ibd_wide = ibd_wide.reset_index(drop=True)
#         ibd_wide.columns = ibd_wide.columns.astype(str)
#         ibd_wide.to_feather(str(output)) 
# 
# rule singlem_kmer_install_pomona_sgc:
#     input: "outputs/singlem_sgc_genome_queries_kmer_hash_tables/normalized_abund_hashes_wide.feather"
#     output:
#         pomona = "outputs/singlem_sgc_genome_queries_kmer_vita_rf/pomona_install.txt"
#     conda: 'envs/rf.yml'
#     resources: 
#         mem_mb=1000
#     threads: 1
#     script: "scripts/install_pomona.R"
# 
# rule singlem_kmer_vita_var_sel_rf_sgc:
#     input:
#         info = "inputs/working_metadata.tsv", 
#         feather = "outputs/singlem_sgc_genome_queries_kmer_hash_tables/normalized_abund_hashes_wide.feather",
#         pomona = "outputs/singlem_sgc_genome_queries_kmer_vita_rf/pomona_install.txt"
#     output:
#         vita_rf = "outputs/singlem_sgc_genome_queries_kmer_vita_rf/{study}_vita_rf.RDS",
#         vita_vars = "outputs/singlem_sgc_genome_queries_kmer_vita_rf/{study}_vita_vars.txt",
#         ibd_filt = "outputs/singlem_sgc_genome_queries_kmer_vita_rf/{study}_ibd_filt.csv"
#     resources: 
#         mem_mb=16000
#     threads: 4
#     params: 
#         threads = 4,
#         validation_study = "{study}"
#     conda: 'envs/rf.yml'
#     script: "scripts/singlem_kmer_vita_rf.R"
# 
# rule singlem_kmer_loo_validation_sgc:
#     input: 
#         ibd_filt = 'outputs/singlem_sgc_genome_queries_kmer_vita_rf/{study}_ibd_filt.csv',
#         info = 'inputs/working_metadata.tsv',
#         eval_model = 'scripts/function_evaluate_model.R',
#         ggconfusion = 'scripts/ggplotConfusionMatrix.R'
#     output: 
#         recommended_pars = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_rec_pars.tsv',
#         optimal_rf = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_optimal_rf.RDS',
#         training_accuracy = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_training_acc.csv',
#         training_confusion = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_training_confusion.pdf',
#         validation_accuracy = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_validation_acc.csv',
#         validation_confusion = 'outputs/singlem_sgc_genome_queries_kmer_optimal_rf/{study}_validation_confusion.pdf'
#     resources: 
#         mem_mb=4000
#     threads: 4
#     params:
#         threads = 4,
#         validation_study = "{study}"
#     conda: 'envs/tuneranger.yml'
#     script: "scripts/tune_rf.R"

############################################################################
## Ribo k-mers model
############################################################################

# same as above, this set of models was never rerun after spacegraphcats was rerun
#rule compute_signatures_singlem:
#    input: "outputs/sgc_genome_queries_singlem_reads/{library}_singlem_reads.fq"
#    output: "outputs/sgc_genome_queries_singlem_sigs/{library}_singlem_reads.sig"
#    conda: "envs/sourmash.yml"
#    shell:'''
#    sourmash compute -k 31 --scaled 2000 -o {output} --track-abundance {input} || touch {output}
#    '''

rule convert_greater_than_1_signatures_to_csv:
    input: "outputs/sgc_genome_queries_singlem_sigs/{library}_singlem_reads.sig"
    output: "outputs/sgc_genome_queries_singlem_kmer_csv/{library}_singlem_reads.csv"
    conda: 'envs/sourmash.yml'
    shell:'''
    python scripts/sig_to_csv.py {input} {output} || touch {output}
    '''

rule make_hash_abund_table_long_normalized:
    input:
        expand("outputs/sgc_genome_queries_singlem_kmer_csv/{library}_singlem_reads.csv", library = LIBRARIES)
    output: csv = "outputs/sgc_genome_queries_singlem_kmer_hash_tables/normalized_abund_hashes_long.csv"
    conda: 'envs/r.yml'
    script: "scripts/normalized_hash_abund_long_singlem.R"

rule make_hash_abund_table_wide:
    input: "outputs/sgc_genome_queries_singlem_kmer_hash_tables/normalized_abund_hashes_long.csv"
    output: "outputs/sgc_genome_queries_singlem_kmer_hash_tables/normalized_abund_hashes_wide.feather"
    run:
        import pandas as pd
        import feather

        ibd = pd.read_csv(str(input), dtype = {"minhash" : "int64", "abund" : "float64", "sample" : "object"})
        ibd_wide=ibd.pivot(index='sample', columns='minhash', values='abund')
        ibd_wide = ibd_wide.fillna(0)
        ibd_wide['sample'] = ibd_wide.index
        ibd_wide = ibd_wide.reset_index(drop=True)
        ibd_wide.columns = ibd_wide.columns.astype(str)
        ibd_wide.to_feather(str(output))

## Random forests & optimization

rule install_pomona:
    input: "outputs/sgc_genome_queries_singlem_kmer_hash_tables/normalized_abund_hashes_wide.feather"
    output:
        pomona = "outputs/sgc_genome_queries_singlem_kmer_vita_rf/pomona_install.txt"
    conda: 'envs/rf.yml'
    script: "scripts/install_pomona.R"

rule vita_var_sel_rf:
    input:
        info = "inputs/working_metadata.tsv",
        feather = "outputs/sgc_genome_queries_singlem_kmer_hash_tables/normalized_abund_hashes_wide.feather",
        pomona = "outputs/sgc_genome_queries_singlem_kmer_vita_rf/pomona_install.txt"
    output:
        vita_rf = "outputs/sgc_genome_queries_singlem_kmer_vita_rf/{study}_vita_rf.RDS",
        vita_vars = "outputs/sgc_genome_queries_singlem_kmer_vita_rf/{study}_vita_vars.txt",
        ibd_filt = "outputs/sgc_genome_queries_singlem_kmer_vita_rf/{study}_ibd_filt.csv"
    params:
        threads = 4,
        validation_study = "{study}"
    conda: 'envs/rf.yml'
    script: "scripts/singlem_kmer_vita_rf.R"

rule loo_validation:
    input:
        ibd_filt = 'outputs/sgc_genome_queries_singlem_kmer_vita_rf/{study}_ibd_filt.csv',
        info = 'inputs/working_metadata.tsv',
        eval_model = 'scripts/function_evaluate_model.R',
        ggconfusion = 'scripts/ggplotConfusionMatrix.R'
    output:
        recommended_pars = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_rec_pars.tsv',
        optimal_rf = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_optimal_rf.RDS',
        training_accuracy = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_training_acc.csv',
        training_confusion = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_training_confusion.pdf',
        validation_accuracy = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_validation_acc.csv',
        validation_confusion = 'outputs/sgc_genome_queries_singlem_kmer_optimal_rf/{study}_validation_confusion.pdf'
    params:
        threads = 4,
        validation_study = "{study}"
    conda: 'envs/tuneranger.yml'
    script: "scripts/tune_rf.R"


